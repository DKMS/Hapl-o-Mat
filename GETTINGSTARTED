Hapl-o-Mat -- Getting started
=============================


Please also see the README.


Introduction
------------
Hapl-o-Mat is software for HLA haplotype inference coded in C++.
Besides estimating haplotype frequencies via an expectation-maximization
algorithm, it is capable of processing HLA genotype population data. This
includes translation of alleles between various typing resolutions and resolving
allelic and genotypic ambiguities. Both common formats for recording
HLA genotypes, multiple allele (NMDP) codes and genotype list strings, are
supported.

This guide explains how to use Hapl-o-Mat under Linux. It is divided into the
following sections:

1) Input Files
2) Data Preparation
3) Input Formats
4) Parameters
5) Install
6) Run Hapl-o-Mat
7) Tutorials

For more information refer to our publications on Hapl-o-Mat:

Journal article to come

C. Schaefer, A.H. Schmidt, J. Sauter. Hapl-O-mat: A Versatile Software for
Haplotype Frequency Estimation. HLA, 2016, 87, 236â€“320


1) Input Files
--------------
Hapl-o-Mat requires the following files to estimate haplotype frequencies:

    Executable: Create the executable "haplomat" via instructions in 5). 

    Input file: A population sample of genotype data to study. See 3) for
    different formats.

    Parameter file: It lists all the parameters required for your run.
    Choose from parametersMA, parametersGLC, parametersGL, or parametersREAD
    according to your input format. See 4) for more information.

    Data: Hapl-o-Mat requires information on the HLA nomenclature in form of some
    files, which have to be placed in the folder data. See 2) for instructions on
    how to get these data.
    

2) Data Preparation
-------------------
The estimation of HLA haplotypes via Hapl-o-Mat requires information on the HLA
nomenclature. You can create this information on your own by following the
instructions in "prepareData/README". For a quick test, you can also use the
data provided in "systemTest/dataSystemTest" (which we also use for the
tutorials). However, depending on how recent your population data is, these data
might be outdated. Then it is possible that Hapl-o-Mat misses multiple allele
codes or allele names. 
Hapl-o-Mat relies on the following files:

   AllAllelesExpanded.txt: A list of relevant existing HLA alleles with their
   enclosed more-digits allele groups.

   Smallg.txt: A list of g-groups with their enclosed alleles in 8-digit resolution.

   LargeG.txt: A list of G-groups with their enclosed alleles in 8-digit resolution.

   P.txt: A list of P-groups with their enclosed alleles in 8-digit resolution.

   MultipleAlleleCodes.txt: A list of multiple allele codes and their translation to
   alleles.

   Ambiguity.txt: Basis for the ambiguity filter.

   AlleleList.txt: If your input data in GL format includes a missing single-locus
   genotype, it can be replaced by combining all alleles of the same locus from this
   file.

The most common HLA loci (HLA-A, B, C, DPA1, DPB1, DQA1, DQB1, DRB1, DRB3, DRB4,
and DRB5) are included in the files. In order to incorporate further loci follow
the instructions in "prepareData/README".


3) Input Formats
----------------
Hapl-o-Mat distinguishes four input formats, which differ in the way the input
population data is recorded. Examples for input data can be found in the
folder "examplePopulations".

    MA: Ambiguities are encoded by multiple allele (MA) codes. Except for the
    first line, input files hold an individual's identification number and
    genotype per line. Genotypes are saved allele by allele without locus name.
    Identification number and alleles are TAB-separated. The first line of the
    file is a header file indicating the name of the first column and the loci
    of the other columns. Same loci must be placed next to each other. For an
    example refer to "examplePopulations/populationData_a.dat".

    GLC: Genotypes with or without ambiguities are saved by genotype list
    strings. Input files hold an individual's identification number and genotype
    per line. Identification number and single-locus genotypes are TAB-separated.
    For an example refer to "examplePopulations/populationData_b.dat"	

    GL: Genotypes with or without ambiguities are saved by genotype list (GL)
    strings. Population data is saved in two files. The pull-file contains an
    individual's identification number and a list of integer numbers, GL-ids,
    referring to its single-locus genotype. The GL-ids are separated from the
    identification number via ";" and, from each other via ":". The second file,
    the glid-file, contains a translation from GL-ids starting with "1" to actual
    single-locus genotypes. GL-id and genotype are separated via ";". A GL-id of
    "0" is interpreted as a missing typing at the corresponding locus and does 
    not require a translation in the glid-file. For an example refer to
    "examplePopulations/populationData_c.pull" and 
    "examplePopulations/populationData_c.glid".

    READ: Ambiguities are completely resolved and alleles are already translated
    to the wanted typing resolutions. The input data is of the format as 
    Hapl-o-Mat writes processed genotype data to file. This allows for easily
    repeating a run without the need to resolve genotype data again.


4) Parameters
-------------
Each input format requires a different set of parameters. All input formats have
the following parameters in common:

    FILENAME_HAPLOTYPES: Name of the file which temporarily saves haplotype names.

    FILENAME_GENOTYPES: Name of the file which saves resolved genotypes.

    FILENAME_HAPLOTYPEFREQUENCIES: Name of the file which saves haplotypes and 
    estimated haplotype frequencies.

    FILENAME_EPSILON_LOGL: Name of the file which saves stopping criterion and 
    log-likelihood per iteration.

    INITIALIZATION_HAPLOTYPEFREQUENCIES: Initialization routine for
    haplotype frequencies. It takes the following values:
    "equal": All haplotype frequencies are initialized with the same frequency.
    "numberOccurrence": Haplotype frequencies are initialized according to the
    initial number of occurrence of the haplotype.
    "random": Haplotype frequencies are initialized randomly.
    "perturbation": Haplotype frequencies are initialized as in numberOccurrence 
    and then randomly modified by a small (<10%) positive or negative offset.

    EPSILON: Value for the stopping criterion, i.e. the maximal change between
    consecutive haplotype frequency estimations is smaller than the assigned
    value.

    CUT_HAPLOTYPEFREQUENCIES: Estimated haplotype frequencies smaller than this
    value are removed from the output.

    RENORMALIZE_HAPLOTYPEFREQUENCIES: Takes values "true" and "false". If 
    "true", normalize estimated haplotype frequencies to sum to one. Within
    machine precision, this becomes necessary, if estimated haplotypes are
    removed, e.g. via the option CUT_HAPLOTYPEFREQUENCIES.

    SEED: Set the seed of the used pseudo random number generator. If set to "0",
    the seed is initialized by the system time.

The parameters are saved in the corresponding files "parametersMA", "parametersGLC",
"parametersGL", and "parametersREAD". Depending on the input format (indicated in
brackets), additional parameters are:

    FILENAME_INPUT (MA, GLC, READ): The file name of the input population data.

    FILENAME_PULL (GL): The file name of the pull-file.

    FILENAME_GLID (GL): The file name of the glid-file.

    LOCI_AND_RESOLUTIONS (MA, GL, GLC): Loci included into analysis and desired
    typing resolution per locus. The list is separated by "," and contains the locus
    name followed by ":" and the desired typing resolution, e.g. A:g,B:4d,C:g.
    Supported typing resolutions and their abbreviations are g-groups (g),
    P-groups (P), G-groups (G), 2-digit fields (2d), 4-digit fields (4d), 6-digit
    fields (6d), and 8-digit fields (8d). Alleles are not translated via the option
    asItIs (applying the ambiguity filter includes an intrinsic translation to
    G-groups).

    LOCIORDER (GL): Specify the order of loci the individual's GL-ids correspond
    to. Loci are separated via ",".

    RESOLVE_MISSING_GENOTYPES(GL): Takes values "true" and "false". If set to
    true, a missing typing is replaced by a combination of all alleles from 
    AlleleList.txt at the locus. Else, individuals with a missing typing are
    discarded from analysis.

    MINIMAL_FREQUENCY_GENOTYPES (MA, GL, GLC): Genotypes which split into more
    genotypes than the inverse of this number are discarded from analysis.

    DO_AMBIGUITYFILTER (MA, GL, GLC): Takes values "true" and "false". The option "true"
    activates the ambiguity filter.

    EXPAND_LINES_AMBIGUITYFILTER (MA, GL, GLC): Takes values "true" and "false". If set to
    "true", matching lines with additional genotype pairs in the ambiguity filter are
    considered.

Whenever specifying a file name including folders, you have to create the folders
before running Hapl-o-Mat.


5) Install
----------
Create the executable "haplomat" via Makefile. Just type in the upper folder (where this
document lives):

    make
    make clean

The executable "haplomat" appears in the same folder.


6) Run Hapl-o-Mat
-----------------

After preparing input data of the format INPUTFORMAT (MA, GLC, GL, READ),
Hapl-o-Mat is run by

      ./haplomat INPUTFORMAT

Hapl-o-Mat prints information on the current run to the screen. This information includes the
used parameters, statistics on the input data, the required memory and time, and error
messages. Depending on the error two things can happen: First, Hapl-o-Mat can just quit. For
example, this happens, if a data file is missing. Second, Hapl-o-Mat does not include a
genotype into analysis. For example, this happens, if the genotype includes a non-existent
HLA allele.


7) Tutorials
------------

In the following we estimate haplotype frequencies from HLA population data in 
different formats. For each input format the population data consists of 100
individuals typed for loci HLA-A, -B, -C, -DPB1, -DQB1, and -DRB1 with varying
typing resolutions.
If you have not done so yet, compile Hapl-o-Mat as explained in 5) which produces the
executable "haplomat".

a) Tutorial with input format MA
You find the relevant population data in "examplePopulations/populationData_a.dat". As
ambiguities are recorded as multiple allele codes, the input format is MA. We are
going to infer three locus (A, B, DRB1) haplotypes from this data. Alleles at
loci A and B shall be translated to typing resolution g and alleles at locus DRB1 to
4-digits typing resolution.

Preparations
Create a folder named "a" and provide the data required by Hapl-o-Mat by copying
the content of folder "systemTest/dataSystemTest" to folder "a/data". The folder must be
named "data" to be found by Hapl-o-Mat. Additionally, copy the executable "haplomat" and
the file "parametersMA" to folder "a".

Parameters
Specify parameters for this run in the file "parametersMA". Start with setting the
file names. The entry of FILENAME_INPUT is defined by the file name of the input
population data. You can copy the file to folder "a" or give a relative path as input.
Let us go with the first way. The entries of the other file names are up to you and
do not need to be changed in other runs. Let's call the temporary file for haplotypes
"run/haplotypes.dat", the file with resolved genotypes "run/genotypes.dat", the file
with the estimated haplotype frequencies "run/hfs.dat", and the file with evolution
of stopping criterion and log-likelihood "run/epsilon.dat". Do not forget to create
the folder "run" before starting Hapl-o-Mat.

Next we set parameters with regard to resolving genotype data. Set the loci to
study (A, B, DRB1) and the associated target allele groups (g, g, 4d) via
LOCI_AND_RESOLUTIONS. The order of loci does not matter. During resolving genotypes,
some genotypes will split into a set of genotypes. We will discard genotypes which
split into more than 100,000 genotypes by setting MINIMAL_FREQUENCY_GENOTYPES to
"0.00001" ("1e-5" also works). We want to resolve the genotype data without applying an
ambiguity filter. Thus you can deactivate the ambiguity filter via
DO_AMBIGUITYFILTER. Since no ambiguity filter is applied, the value of
EXPAND_LINES_AMBIGUITYFILTER does not matter. However, for consistency we set it to
"false".

Finally, we enter parameters relevant for haplotype frequency estimation.
Initialize haplotype frequencies randomly by setting 
INITIALIZATION_HAPLOTYPEFREQUENCIES to the corresponding value. We want a stopping
criterion of 0.00001 and discard final estimated haplotype frequencies with a
frequency smaller than this value (hint: change parameters EPSILON and
CUT_HAPLOTYPEFREQUENCIES). Since we remove haplotypes from the final set, a 
normalization of the remaining haplotypes might be a good idea. Just activate the
normalization of haplotypes via RENORMALIZE_HAPLOTYPEFREQUENCIES. If you use random
initial haplotype frequencies (random or perturbation), the parameter SEED is relevant
for setting the seed of the pseudo random number generator. Set it to "1000".

If you have followed the instructions exactly, your parameter file should look
like this:

    #file names
    FILENAME_INPUT=populationData_a.dat
    FILENAME_HAPLOTYPES=run/haplotypes.dat
    FILENAME_GENOTYPES=run/genotypes.dat
    FILENAME_HAPLOTYPEFREQUENCIES=run/hfs.dat
    FILENAME_EPSILON_LOGL=run/epsilon.dat
    #reports
    LOCI_AND_RESOLUTIONS=A:g,B:g,DRB1:4d
    MINIMAL_FREQUENCY_GENOTYPES=1e-5
    DO_AMBIGUITYFILTER=false
    EXPAND_LINES_AMBIGUITYFILTER=false
    #EM-algorithm
    INITIALIZATION_HAPLOTYPEFREQUENCIES=random
    EPSILON=1e-5
    CUT_HAPLOTYPEFREQUENCIES=1e-5
    RENORMALIZE_HAPLOTYPEFREQUENCIES=true
    SEED=1000

Run Hapl-o-Mat and examine results
If you are not already there, go to folder "a" and run Hapl-o-Mat via

    ./haplomat MA     

It produces some output on the screen including your chosen parameters, statistics
on the resolved genotype data and the expectation-maximization algorithm, and the
run time. You can easily write this output to an extra file by starting Hapl-o-Mat
with

    ./haplomat MA > Log.dat

Now let's examine the results produced by Hapl-o-Mat. We first look into the file
with the resolved genotypes, "run/genotypes.dat". The first column corresponds to
the individual's identification number. The second column indicates how ambiguities
per single-locus genotypes have been resolved. If no ambiguity occurred or no
additional genotypes are formed, the type is N. If an ambiguity occurred and was
resolved via building all possible allele combinations, the type is I. Activating
the ambiguity filter gives additional types: A, if one matching line in the ambiguity
file was found, and M if multiple matching lines were found. The third column gives
the frequency of the genotype and the fourth column the genotype itself. The genotype
is saved in the GL format. If an individual's genotype splits into a set of genotypes,
each genotype is written to one line starting with the same identification number. The
corresponding frequencies become non-integer and sum to one.

The evolution of the stopping criterion and log-likelihood while iterating
expectation and maximization steps is written to "run/epsilon.dat". The first
column is the stopping criterion and the second one the not normalized
log-likelihood.

The inferred haplotypes including estimated frequencies are listed in "run/hfs.dat".
Haplotypes are saved in the GL format. This is the file you were aiming at. It is
sorted by descending frequency and already normalized if you activated the
corresponding option (we did in this tutorial).

b) Tutorial with input format GLC
This time ambiguities in the genotypic population data are recorded via genotype
list strings. The file with the population data is called "populationData_b.glc".
As all the information is in one file, the input format is GLC. Running Hapl-o-Mat
works exactly as in tutorial a). You just use the parameter file "parametersGLC"
instead of "parametersMA" and make the appropriate changes. Compared to tutorial a)
the population data contains different genotypes. So do not wonder that you obtain
different results. Run Hapl-o-Mat in folder "b" with

    ./haplomat GLC

c) Tutorial with input format GL
Again, ambiguities in the genotypic population data are recorded via genotype list
strings. Since the data is saved in two different files, the input format is GL.
Follow the steps from tutorial a), but use the parameter file "parametersGL". The 
file names for the population data are "populationData_c.pull" and 
"populationData_c.glid". I guess, you can figure out the matching positions in the
parameter file. GL input format requires the order of loci as input, which can be
obtained by looking in the pull- and glid-file. The first individual from
"populationData_c.pull" has GL-ids 1, 2, 3, 4, 5, and 6. We know from 
"populationData_c.pull" that they correspond to loci B, A, DPB1, DRB1, C, and DQB1,
respectively. Because of that we set "LOCIORDER=B,A,DPB1,DRB1,C,DQB1". Finally, set
the additional option RESOLVE_MISSING_GENOTYPE to "false". Run Hapl-o-Mat in folder
"c" with

    ./haplomat GL
   
d) Tutorial with input format READ
Finally, we test the input format READ. Create a folder "d" and copy one file with
resolved genotypes, say "a/run/genotypes.dat" there. Add "haplomat", "data", and
"parametersREAD" to this folder. Using the input format READ Hapl-o-Mat does not
resolve ambiguities or translates alleles, but reads in already resolved genotype
data. Because of that the parameter file misses some options. Just adjust the file
names and set parameters for the haplotype frequency estimation. Run Hapl-o-Mat in
folder "d" via

    ./haplomat READ
